worker:
  # Connection settings
  server: "ws://localhost:8765" # or wss:// for SSL
  token: "example-worker-token"

  # Local GPU selection
  gpu_id: 1 # Which GPU to use on this machine
  vllm: true

  # Local queue settings
  readahead_size: 256 # Maximum items in readahead queue
  inference_queue_size: 128 # Maximum batches in inference queue
